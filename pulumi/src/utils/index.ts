import * as path from 'path';
import * as fs from 'fs';
import * as os from 'os';
import { execSync } from 'child_process';
import { ProjectConfig } from '../core/project';
import { S3Client, HeadBucketCommand, CreateBucketCommand, PutBucketVersioningCommand, BucketLocationConstraint } from '@aws-sdk/client-s3';
import { STS } from '@aws-sdk/client-sts'

declare global {
  /** Root path of the git repository */
  var projectRoot: string;
  /** 
   * Config directory path (.config)
   * Used to store AWS config file, Kubernetes config and similar configuration files
   */
  var projectConfigPath: string;
  /** Git remote origin URL */
  var gitOrigin: string;
}

/**
 * Utility class providing helper methods for project configuration and AWS setup
 */
export class Utils {

  /**
   * Generates AWS config file based on project configuration
   * Creates SSO profiles for each environment and default SSO session
   * @param projectConfig - Project configuration object
   */
  public static generateAwsConfigFile(projectConfig: ProjectConfig | undefined) {
    //TODO(OP): Add other authentication method
    if (!projectConfig) return;
    if (!projectConfig.aws?.sso_config) return;
    
    const projectId = projectConfig.id;
    const ssoUrl = projectConfig.aws.sso_config.sso_url;
    const ssoRegion = projectConfig.aws.sso_config.sso_region;
    const ssoRoleName = projectConfig.aws.sso_config.sso_role_name;
    const environments = projectConfig.environments || {};

    let configContent = `\
[default]
sso_session = ${projectId}
region = ${ssoRegion}
`
    Object.entries(environments).forEach(([envId, config]) => {
      if (!config.awsConfig) return;
      configContent += `
[profile ${projectId}-${envId}]
sso_session = ${projectId}
sso_account_id = ${config.awsConfig.accountId}
sso_role_name = ${ssoRoleName}
region = ${config.awsConfig.region}
`
    })
    configContent += `
[sso-session ${projectId}]
sso_start_url = ${ssoUrl}
sso_region = ${ssoRegion}
sso_registration_scopes = sso:account:access\
`
    fs.writeFileSync(`${projectConfigPath}/aws_config`, '# Generated by Pulumi\n' + configContent);
  };

  /**
   * Checks if S3 bucket exists and creates it if not
   * Handles AWS SSO authentication and enables versioning on the bucket
   * @param config - S3 backend configuration
   */
  // Minimal shape needed for S3 bucket bootstrap
  public static async checkCreateS3Bucket(config: { bucket: string; region?: string; profile?: string; sharedConfigFiles?: string[] }) {
    if (execSync('id -u').toString().trim() === '999') {
      return
    }
    if (config.sharedConfigFiles && config.sharedConfigFiles[0]) {
      process.env.AWS_CONFIG_FILE = config.sharedConfigFiles[0];
    }
    const client = new S3Client({
      region: config.region,
      profile: config.profile,
    })

    try {
      // Check if bucket exists
      try {
        await client.send(new HeadBucketCommand({ Bucket: config.bucket }));
        return;
      } catch (error: any) {
        if (error.$metadata?.httpStatusCode !== 404) {
          console.log(`Failed to check if S3 bucket exists: ${error.message}`);
          return;
        }
      }

      // Create bucket
      await client.send(new CreateBucketCommand({
        Bucket: config.bucket,
        CreateBucketConfiguration: {
          LocationConstraint: config.region as BucketLocationConstraint
        }
      }));

      // Enable versioning
      await client.send(new PutBucketVersioningCommand({
        Bucket: config.bucket,
        VersioningConfiguration: {
          Status: 'Enabled'
        }
      }));
    } catch (error: any) {
      console.log(`S3 bucket operation failed: ${error.message}`);
    }
  }

  /**
   * Checks if a GCS bucket exists and creates it if not (uses gcloud CLI if available).
   */
  public static async checkCreateGcsBucket(config: { bucket: string; location?: string }) {
    try {
      execSync('gcloud --version', { stdio: 'ignore' });
    } catch {
      // gcloud not available; skip
      return;
    }
    const isContainer = (() => { try { return execSync('id -u').toString().trim() === '999'; } catch { return false; } })();
    const allowInteractive = process.stdout.isTTY && !isContainer && process.env.GCP_INTERACTIVE_LOGIN !== 'false';
    const maybeReauth = (err: any) => {
      if (!allowInteractive) return false;
      const msg = [err?.stderr?.toString?.(), err?.stdout?.toString?.(), err?.message]
        .filter(Boolean)
        .join('\n');
      if (!msg) return false;
      const needs = /Reauthentication required|login required|invalid_grant|permission denied|unauthorized/i.test(msg);
      if (needs) {
        try { execSync('gcloud auth login --update-adc', { stdio: 'inherit' }); return true; } catch { return false; }
      }
      return false;
    };
    const normalizeLocation = (loc?: string) => {
      if (!loc) return 'US';
      // Allow AWS-style shortcodes like eu-west3 -> europe-west3
      if (loc.startsWith('eu-') && !loc.startsWith('europe-')) {
        return loc.replace(/^eu-/, 'europe-');
      }
      return loc;
    };
    try {
      // Describe bucket; if it fails, create it
      execSync(`gcloud storage buckets describe gs://${config.bucket}`, { stdio: 'ignore' });
      return;
    } catch (err: any) {
      // Try to re-auth and re-check once if needed
      if (maybeReauth(err)) {
        try {
          execSync(`gcloud storage buckets describe gs://${config.bucket}`, { stdio: 'ignore' });
          return;
        } catch {}
      }
    }
    try {
      const location = normalizeLocation(config.location);
      execSync(`gcloud storage buckets create gs://${config.bucket} --location=${location}`, { stdio: 'inherit' });
    } catch (e) {
      // Retry once after interactive auth if needed
      if (maybeReauth(e)) {
        try {
          const location = normalizeLocation(config.location);
          execSync(`gcloud storage buckets create gs://${config.bucket} --location=${location}`, { stdio: 'inherit' });
          return;
        } catch (e2) {
          console.error(`Failed to create GCS bucket ${config.bucket}:`, (e2 as any)?.message || e2);
          return;
        }
      }
      console.error(`Failed to create GCS bucket ${config.bucket}:`, (e as any)?.message || e);
    }
  }

  /**
   * Creates project configuration directory if it doesn't exist
   * @param scope - CDK construct scope for error annotations
   * @param path - Optional custom path for config directory
   */
  public static createProjectConfigPath(p?: string) {
    const dir = p || projectConfigPath;
    try {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    } catch (error: any) {
      console.error(error);
    }
  }

  /**
   * Initializes global variables for project paths and git configuration
   * Sets projectRoot, projectConfigPath, and gitOrigin
   */
  public static setGlobalVariables() {
    global.projectRoot = execSync('git rev-parse --show-toplevel').toString().trim()
    global.projectConfigPath = path.resolve(projectRoot, '.config');
    global.gitOrigin = execSync('git config --get remote.origin.url').toString().trim();
  }

  public static async refreshSsoSession(config: ProjectConfig) {
    if (!config.aws?.sso_config) return;
    const configFile = fs.existsSync(`${projectConfigPath}/aws_config`) ? `${projectConfigPath}/aws_config` : '~/.aws/config';

    process.env.AWS_CONFIG_FILE = configFile;
    try {
      await new STS({
        region: config.aws.sso_config.sso_region,
        profile: 'nebra-dev'
      }).getCallerIdentity({});
    } catch (error: any) {
      if (error.message.includes("To refresh this SSO session run 'aws sso login'") ) {
        execSync(`aws sso login`);
      }
    }
  }

  /**
   * Bootstrap GCP auth so Pulumi gcp provider can use ADC (Application Default Credentials).
   * - Ensures .config exists
   * - Sets GOOGLE_APPLICATION_CREDENTIALS to existing ADC json if available
   * - Optionally sets gcloud active project and quota project if gcloud is installed
   * NOTE: This does not perform interactive login. If ADC is missing, it will suggest running:
   *   gcloud auth application-default login
   */
  public static bootstrapGcp(projectId: string | undefined) {
    try {
      if (!fs.existsSync(projectConfigPath)) fs.mkdirSync(projectConfigPath, { recursive: true });
      const home = os.homedir();
      const defaultAdcPath = path.resolve(home, '.config', 'gcloud', 'application_default_credentials.json');

      // Prefer explicit env var, otherwise use default ADC file if present
      const currentGac = process.env.GOOGLE_APPLICATION_CREDENTIALS;
      if (currentGac && fs.existsSync(currentGac)) {
        process.env.GOOGLE_APPLICATION_CREDENTIALS = currentGac;
      } else if (fs.existsSync(defaultAdcPath)) {
        process.env.GOOGLE_APPLICATION_CREDENTIALS = defaultAdcPath;
      }

      // If gcloud is available, set project and quota project (non-interactive)
      try {
        execSync('gcloud --version', { stdio: 'ignore' });
        if (projectId) {
          try { execSync(`gcloud config set project ${projectId}`, { stdio: 'ignore' }); } catch {}
          try { execSync(`gcloud auth application-default set-quota-project ${projectId}`, { stdio: 'ignore' }); } catch {}
        }
      } catch {
        // gcloud not installed; skip silently
      }

      // If no ADC yet, open browser for interactive login (ADC), unless disabled
      const adcPath = process.env.GOOGLE_APPLICATION_CREDENTIALS;
      const hasAdc = adcPath && fs.existsSync(adcPath);
      let gcloudAvailable = false;
      try { execSync('gcloud --version', { stdio: 'ignore' }); gcloudAvailable = true; } catch {}
      const isContainer = (() => { try { return execSync('id -u').toString().trim() === '999'; } catch { return false; } })();
      if (!hasAdc && gcloudAvailable && process.stdout.isTTY && !isContainer && process.env.GCP_INTERACTIVE_LOGIN !== 'false') {
        try {
          execSync('gcloud auth application-default login --update-adc', { stdio: 'inherit' });
          if (!process.env.GOOGLE_APPLICATION_CREDENTIALS && fs.existsSync(defaultAdcPath)) {
            process.env.GOOGLE_APPLICATION_CREDENTIALS = defaultAdcPath;
          }
          if (projectId) {
            try { execSync(`gcloud config set project ${projectId}`, { stdio: 'ignore' }); } catch {}
            try { execSync(`gcloud auth application-default set-quota-project ${projectId}`, { stdio: 'ignore' }); } catch {}
          }
        } catch {}
      }

      // If we still don't have ADC, emit a helpful hint
      if (!process.env.GOOGLE_APPLICATION_CREDENTIALS || !fs.existsSync(process.env.GOOGLE_APPLICATION_CREDENTIALS)) {
        const hintPath = path.resolve(projectConfigPath, 'GCP_AUTH_HINT');
        if (!fs.existsSync(hintPath)) {
          fs.writeFileSync(hintPath, `No ADC found. Run:\n  gcloud auth application-default login\nThen re-run deployment. Project: ${projectId ?? 'unknown'}\n`);
        }
      }
    } catch {}
  }

  /**
   * Resolve Pulumi backend URL for a given environment.
   */
  public static resolveBackendUrl(params: { projectId: string; envId: string; backend?: string | BackendConfig; aws?: { region?: string; profile?: string; sharedConfigFiles?: string[] }; gcp?: { projectId?: string; region?: string } }): string {
    const { projectId, envId, backend, aws, gcp } = params;
    // Explicit backend selection (string URL or local path)
    if (typeof backend === 'string' && backend.trim().length > 0) {
      const b = backend.trim();
      if (b.startsWith('s3://') || b.startsWith('gs://') || b.startsWith('file://')) {
        return b;
      }
      // Treat as local directory path
      const target = path.isAbsolute(b) ? b : path.resolve(projectRoot, b);
      try { if (!fs.existsSync(target)) fs.mkdirSync(target, { recursive: true }); } catch {}
      return `file://${target}`;
    }
    // Backward-compatible explicit object variant
    if ((backend as BackendConfig)?.type === 's3') {
      const s3 = backend as BackendS3;
      const bucket = s3.bucket || `${projectId}-${envId}-tfstate`;
      return `s3://${bucket}`;
    }
    if ((backend as BackendConfig)?.type === 'gcs') {
      const gcs = backend as BackendGcs;
      return `gs://${gcs.bucket}`;
    }
    if ((backend as BackendConfig)?.type === 'file') {
      const f = backend as BackendFile;
      const target = f.path || path.resolve(projectRoot, '.pulumi-state');
      try { if (!fs.existsSync(target)) fs.mkdirSync(target, { recursive: true }); } catch {}
      return `file://${target}`;
    }
    // Implicit: prefer S3 when AWS is configured
    if (aws) {
      const bucket = `${projectId}-${envId}-tfstate`;
      return `s3://${bucket}`;
    }
    // Implicit: prefer GCS when GCP is configured
    if (gcp) {
      const bucket = `pulumi-${projectId}-${envId}-state`;
      return `gs://${bucket}`;
    }
    const dir = path.resolve(projectRoot, '.pulumi-state');
    try { if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true }); } catch {}
    return `file://${dir}`;
  }

  /**
   * Ensure a Pulumi passphrase exists for the default secrets provider.
   * Returns the passphrase and writes it to .config/pulumi_passphrase if newly generated.
   */
  public static ensurePulumiPassphrase(): string {
    const existing = process.env.PULUMI_CONFIG_PASSPHRASE;
    if (existing && existing.length > 0) return existing;
    const file = path.resolve(projectConfigPath, 'pulumi_passphrase');
    try {
      if (fs.existsSync(file)) {
        const v = fs.readFileSync(file, 'utf8').trim();
        if (v) return v;
      }
    } catch {}
    const rand = execSync('openssl rand -base64 32 || uuidgen || date +%s').toString().trim();
    try { fs.writeFileSync(file, rand, { mode: 0o600 }); } catch {}
    return rand;
  }

  /**
   * Ensure remote backend storage exists for the given backend URL.
   * Supports s3:// and gs:// when corresponding cloud config is provided.
   */
  public static async ensureBackendForUrl(params: { backendUrl?: string; aws?: { region?: string; profile?: string; sharedConfigFiles?: string[] }; gcp?: { region?: string } }) {
    const { backendUrl, aws, gcp } = params;
    if (!backendUrl) return;
    if (backendUrl.startsWith('s3://') && aws) {
      const bucket = backendUrl.replace('s3://', '').split('/')[0];
      await Utils.checkCreateS3Bucket({
        bucket,
        region: aws.region,
        profile: aws.profile,
        sharedConfigFiles: aws.sharedConfigFiles,
      });
      return;
    }
    if (backendUrl.startsWith('gs://') && gcp) {
      const bucket = backendUrl.replace('gs://', '').split('/')[0];
      await Utils.checkCreateGcsBucket({ bucket, location: gcp.region });
    }
  }
}

export type BackendS3 = { type: 's3'; bucket?: string; region?: string; profile?: string; sharedConfigFiles?: string[] };
export type BackendGcs = { type: 'gcs'; bucket: string; location?: string };
export type BackendFile = { type: 'file'; path?: string };
export type BackendConfig = BackendS3 | BackendGcs | BackendFile;


