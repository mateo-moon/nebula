import * as path from 'path';
import * as fs from 'fs';
import * as os from 'os';
import * as YAML from 'yaml';
import { execSync, execFileSync } from 'child_process';
import { S3Client, HeadBucketCommand, CreateBucketCommand, PutBucketVersioningCommand, BucketLocationConstraint } from '@aws-sdk/client-s3';
import { KeyManagementServiceClient } from '@google-cloud/kms';

declare global {
  /** Root path of the git repository */
  var projectRoot: string;
  /** 
   * Config directory path (.config)
   * Used to store AWS config file, Kubernetes config and similar configuration files
   */
  var projectConfigPath: string;
  /** Git remote origin URL */
  var gitOrigin: string;
}

/**
 * Utility class providing helper methods for project configuration and AWS setup
 */
export class Utils {

  /**
   * Generates AWS config file based on project configuration
   * Creates SSO profiles for each environment and default SSO session
   * @param projectConfig - Project configuration object
   */
//   public static generateAwsConfigFile(projectConfig: ProjectConfig | undefined) {
//     //TODO(OP): Add other authentication method
//     if (!projectConfig) return;
//     if (!projectConfig.awsConfig?.sso_config) return;
    
//     const projectId = projectConfig.id;
//     const ssoUrl = projectConfig.awsConfig.sso_config.sso_url;
//     const ssoRegion = projectConfig.awsConfig.sso_config.sso_region;
//     const ssoRoleName = projectConfig.awsConfig.sso_config.sso_role_name;
//     const environments = projectConfig.environments || {};

//     let configContent = `\
// [default]
// sso_session = ${projectId}
// region = ${ssoRegion}
// `
//     Object.entries(environments).forEach(([envId, config]) => {
//       if (!(config as any).awsConfig) return;
//       configContent += `
// [profile ${projectId}-${envId}]
// sso_session = ${projectId}
// sso_account_id = ${(config as any).awsConfig.accountId}
// sso_role_name = ${ssoRoleName}
// region = ${(config as any).awsConfig.region}
// `
//     })
//     configContent += `
// [sso-session ${projectId}]
// sso_start_url = ${ssoUrl}
// sso_region = ${ssoRegion}
// sso_registration_scopes = sso:account:access\
// `
//     fs.writeFileSync(`${projectConfigPath}/aws_config`, '# Generated by Pulumi\n' + configContent);
//   };

  /**
   * Checks if S3 bucket exists and creates it if not
   * Handles AWS SSO authentication and enables versioning on the bucket
   * @param config - S3 backend configuration
   */
  // Minimal shape needed for S3 bucket bootstrap
  public static async checkCreateS3Bucket(config: { bucket: string; region?: string; profile?: string; sharedConfigFiles?: string[] }) {
    if (execSync('id -u').toString().trim() === '999') {
      return
    }
    if (config.sharedConfigFiles && config.sharedConfigFiles[0]) {
      process.env['AWS_CONFIG_FILE'] = config.sharedConfigFiles[0];
    }
    if (config.profile) {
      process.env['AWS_PROFILE'] = config.profile;
      process.env['AWS_SDK_LOAD_CONFIG'] = '1';
    }
    const client = new S3Client({
      ...(config.region ? { region: config.region } : {}),
    })

    try {
      // Check if bucket exists
      try {
        await client.send(new HeadBucketCommand({ Bucket: config.bucket }));
        return;
      } catch (error: any) {
        if (error.$metadata?.httpStatusCode !== 404) {
          console.log(`Failed to check if S3 bucket exists: ${error.message}`);
          return;
        }
      }

      // Create bucket
      const needsLocation = !!config.region && config.region !== 'us-east-1';
      const params: any = { Bucket: config.bucket };
      if (needsLocation) params.CreateBucketConfiguration = { LocationConstraint: config.region as BucketLocationConstraint };
      await client.send(new CreateBucketCommand(params));

      // Enable versioning
      await client.send(new PutBucketVersioningCommand({
        Bucket: config.bucket,
        VersioningConfiguration: {
          Status: 'Enabled'
        }
      }));
    } catch (error: any) {
      console.log(`S3 bucket operation failed: ${error.message}`);
    }
  }

  /**
   * Checks if a GCS bucket exists and creates it if not (uses gcloud CLI if available).
   */
  public static async checkCreateGcsBucket(config: { bucket: string; location?: string }) {
    try {
      execSync('gcloud --version', { stdio: 'ignore' });
    } catch {
      // gcloud not available; skip
      return;
    }
    const isContainer = (() => { try { return execSync('id -u').toString().trim() === '999'; } catch { return false; } })();
    const allowInteractive = process.stdout.isTTY && !isContainer && process.env['GCP_INTERACTIVE_LOGIN'] !== 'false';
    const maybeReauth = (err: any) => {
      if (!allowInteractive) return false;
      const msg = [err?.stderr?.toString?.(), err?.stdout?.toString?.(), err?.message]
        .filter(Boolean)
        .join('\n');
      if (!msg) return false;
      const needs = /Reauthentication required|login required|invalid_grant|permission denied|unauthorized/i.test(msg);
      if (needs) {
        try { execSync('gcloud auth login --update-adc', { stdio: 'inherit' }); return true; } catch { return false; }
      }
      return false;
    };
    const normalizeLocation = (loc?: string) => {
      if (!loc) return 'US';
      // Allow AWS-style shortcodes like eu-west3 -> europe-west3
      if (loc.startsWith('eu-') && !loc.startsWith('europe-')) {
        return loc.replace(/^eu-/, 'europe-');
      }
      return loc;
    };
    try {
      // Describe bucket; if it fails, create it
      execSync(`gcloud storage buckets describe gs://${config.bucket} --quiet`, { stdio: 'ignore' });
      return;
    } catch (err: any) {
      // Try to re-auth and re-check once if needed
      if (maybeReauth(err)) {
        try {
          execSync(`gcloud storage buckets describe gs://${config.bucket} --quiet`, { stdio: 'ignore' });
          return;
        } catch {}
      }
    }
    try {
      const location = normalizeLocation(config.location || undefined);
      execSync(`gcloud storage buckets create gs://${config.bucket} --location=${location} --quiet`, { stdio: 'inherit' });
    } catch (e) {
      // Retry once after interactive auth if needed
      if (maybeReauth(e)) {
        try {
          const location = normalizeLocation(config.location || undefined);
          execSync(`gcloud storage buckets create gs://${config.bucket} --location=${location} --quiet`, { stdio: 'inherit' });
          return;
        } catch (e2: any) {
          console.error(`Failed to create GCS bucket ${config.bucket}:`, e2?.message || e2);
          return;
        }
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const err: any = e;
      console.error(`Failed to create GCS bucket ${config.bucket}:`, err?.message || e);
    }
  }

  /**
   * Creates project configuration directory if it doesn't exist
   * @param scope - CDK construct scope for error annotations
   * @param path - Optional custom path for config directory
   */
  public static createProjectConfigPath(p?: string) {
    const dir = p || projectConfigPath;
    try {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    } catch (error: any) {
      console.error(error);
    }
  }

  /**
   * Initializes global variables for project paths and git configuration
   * Sets projectRoot, projectConfigPath, and gitOrigin
   */
  public static setGlobalVariables() {
    global.projectRoot = execSync('git rev-parse --show-toplevel').toString().trim()
    global.projectConfigPath = path.resolve(projectRoot, '.config');
    global.gitOrigin = execSync('git config --get remote.origin.url').toString().trim();
  }

  // public static async refreshSsoSession(config: ProjectConfig) {
  //   if (!config.awsConfig?.sso_config) return;
  //   const configFile = fs.existsSync(`${projectConfigPath}/aws_config`) ? `${projectConfigPath}/aws_config` : '~/.aws/config';

  //   process.env.AWS_CONFIG_FILE = configFile;
  //   try {
  //     await new STS({
  //       region: config.awsConfig.sso_config.sso_region,
  //       profile: 'nebra-dev'
  //     }).getCallerIdentity({});
  //   } catch (error: any) {
  //     if (error.message.includes("To refresh this SSO session run 'aws sso login'") ) {
  //       execSync(`aws sso login`);
  //     }
  //   }
  // }

  /**
   * Bootstrap GCP auth so Pulumi gcp provider can use ADC (Application Default Credentials).
   * - Ensures .config exists
   * - Sets GOOGLE_APPLICATION_CREDENTIALS to existing ADC json if available
   * - Optionally sets gcloud active project and quota project if gcloud is installed
   * NOTE: This does not perform interactive login. If ADC is missing, it will suggest running:
   *   gcloud auth application-default login
   */
  public static bootstrapGcp(projectId: string | undefined) {
    try {
      if (!fs.existsSync(projectConfigPath)) fs.mkdirSync(projectConfigPath, { recursive: true });
      const home = os.homedir();
      const defaultAdcPath = path.resolve(home, '.config', 'gcloud', 'application_default_credentials.json');

      // Prefer explicit env var, otherwise use default ADC file if present
      const currentGac = process.env['GOOGLE_APPLICATION_CREDENTIALS'];
      if (currentGac && fs.existsSync(currentGac)) {
        process.env['GOOGLE_APPLICATION_CREDENTIALS'] = currentGac;
      } else if (fs.existsSync(defaultAdcPath)) {
        process.env['GOOGLE_APPLICATION_CREDENTIALS'] = defaultAdcPath;
      }

      // If gcloud is available, set project and quota project (non-interactive)
      try {
        execSync('gcloud --version', { stdio: 'ignore' });
        if (projectId) {
          try { execSync(`gcloud config set project ${projectId}`, { stdio: 'ignore' }); } catch {}
          try { execSync(`gcloud auth application-default set-quota-project ${projectId}`, { stdio: 'ignore' }); } catch {}
        }
      } catch {
        // gcloud not installed; skip silently
      }

      // If no ADC yet, open browser for interactive login (ADC), unless disabled
      const adcPath = process.env['GOOGLE_APPLICATION_CREDENTIALS'];
      const hasAdc = adcPath ? fs.existsSync(adcPath) : false;
      let gcloudAvailable = false;
      try { execSync('gcloud --version', { stdio: 'ignore' }); gcloudAvailable = true; } catch {}
      const isContainer = (() => { try { return execSync('id -u').toString().trim() === '999'; } catch { return false; } })();
      if (!hasAdc && gcloudAvailable && process.stdout.isTTY && !isContainer && process.env['GCP_INTERACTIVE_LOGIN'] !== 'false') {
        try {
          execSync('gcloud auth application-default login --update-adc', { stdio: 'inherit' });
          if (!process.env['GOOGLE_APPLICATION_CREDENTIALS'] && fs.existsSync(defaultAdcPath)) {
            process.env['GOOGLE_APPLICATION_CREDENTIALS'] = defaultAdcPath;
          }
          if (projectId) {
            try { execSync(`gcloud config set project ${projectId}`, { stdio: 'ignore' }); } catch {}
            try { execSync(`gcloud auth application-default set-quota-project ${projectId}`, { stdio: 'ignore' }); } catch {}
          }
        } catch {}
      }

      // If we still don't have ADC, emit a helpful hint
      if (!process.env['GOOGLE_APPLICATION_CREDENTIALS'] || !fs.existsSync(process.env['GOOGLE_APPLICATION_CREDENTIALS'] as string)) {
        const hintPath = path.resolve(projectConfigPath, 'GCP_AUTH_HINT');
        if (!fs.existsSync(hintPath)) {
          fs.writeFileSync(hintPath, `No ADC found. Run:\n  gcloud auth application-default login\nThen re-run deployment. Project: ${projectId ?? 'unknown'}\n`);
        }
      }
    } catch {}
  }

  /**
   * Ensure remote backend storage exists for the given backend URL.
   * Supports s3:// and gs:// when corresponding cloud config is provided.
   */
  public static async ensureBackendForUrl(params: { backendUrl?: string; aws?: { region?: string; profile?: string; sharedConfigFiles?: string[] }; gcp?: { region?: string } }) {
    const { backendUrl, aws, gcp } = params;
    if (!backendUrl) return;
    if (backendUrl.startsWith('s3://') && aws) {
      const bucket = backendUrl.replace('s3://', '').split('/')[0];
      await Utils.checkCreateS3Bucket({
        bucket,
        ...(aws.region ? { region: aws.region } : {}),
        ...(aws.profile ? { profile: aws.profile } : {}),
        ...(aws.sharedConfigFiles ? { sharedConfigFiles: aws.sharedConfigFiles } : {}),
      } as any);
      return;
    }
    if (backendUrl.startsWith('gs://') && gcp) {
      const bucket = backendUrl.replace('gs://', '').split('/')[0];
      await Utils.checkCreateGcsBucket({ bucket, ...(gcp.region ? { location: gcp.region } : {}) } as any);
    }
  }

  /** Ensure secrets provider resources exist before workspace init. For now: supports gcpkms:// only. */
  public static async ensureSecretsProvider(params: { secretsProviders?: string[] }) {
    const providers = Array.from(new Set((params.secretsProviders || []).filter(Boolean))) as string[];
    for (const p of providers) {
      if (!p) continue;
      if (p.startsWith('gcpkms://')) {
        try { await Utils.ensureGcpKmsKeyFromUrl(p); } catch (e: any) { console.error(e?.message || e); }
      }
    }
  }

  private static async ensureGcpKmsKeyFromUrl(providerUrl: string) {
    const resource = providerUrl.replace(/^gcpkms:\/\//, '');
    const m = resource.match(/^projects\/([^/]+)\/locations\/([^/]+)\/keyRings\/([^/]+)\/cryptoKeys\/([^/?#]+)$/);
    if (!m) {
      console.error(`Unsupported gcpkms provider format: ${providerUrl}`);
      return;
    }
    const [, projectId, location, ringId, keyId] = m;
    const kms = new KeyManagementServiceClient();
    const ringName = `projects/${projectId}/locations/${location}/keyRings/${ringId}`;
    const keyName = `projects/${projectId}/locations/${location}/keyRings/${ringId}/cryptoKeys/${keyId}`;
    const parentLoc = `projects/${projectId}/locations/${location}`;

    // Ensure KeyRing exists
    const ringExists = async () => { try { await kms.getKeyRing({ name: ringName }); return true; } catch { return false; } };
    if (!(await ringExists())) {
      try { await kms.createKeyRing({ parent: parentLoc, keyRingId: ringId ?? null, keyRing: {} } as any); }
      catch (e: any) {
        // Ignore already exists; otherwise log
        if (!/Already exists|ALREADY_EXISTS/i.test(e?.message || '')) console.error(`Failed to create KeyRing ${ringName}:`, e?.message || e);
      }
    }

    // Ensure CryptoKey exists
    const keyExists = async () => { try { await kms.getCryptoKey({ name: keyName }); return true; } catch { return false; } };
    if (!(await keyExists())) {
      try {
        const nowSeconds = Math.floor(Date.now() / 1000);
        await kms.createCryptoKey({
          parent: ringName,
          cryptoKeyId: (keyId ?? null) as any,
          cryptoKey: {
            purpose: 'ENCRYPT_DECRYPT',
            rotationPeriod: { seconds: 7776000 },
            nextRotationTime: { seconds: nowSeconds + 7776000 },
          },
        });
      } catch (e: any) {
        if (!/Already exists|ALREADY_EXISTS/i.test(e?.message || '')) console.error(`Failed to create CryptoKey ${keyName}:`, e?.message || e);
      }
    } else {
      // Ensure primary version is ENABLED; if not, create a new version and set it primary
      try {
        const [ck] = await kms.getCryptoKey({ name: keyName });
        const primary = ck?.primary?.name;
        if (primary) {
          const [ver] = await kms.getCryptoKeyVersion({ name: primary });
          if (ver.state !== 'ENABLED') {
            const [newVer] = await kms.createCryptoKeyVersion({ parent: keyName, cryptoKeyVersion: {} });
            const newId = (newVer?.name || '').split('/').pop();
            if (newId) {
              await kms.updateCryptoKeyPrimaryVersion({ name: keyName, cryptoKeyVersionId: newId });
            }
          }
        }
      } catch (e: any) {
        console.error(`Failed to verify/rotate primary version for ${keyName}:`, e?.message || e);
      }
    }
  }

  /** Resolve refs via vals (e.g., ref+sops://...). Returns trimmed stdout or throws. */
  public static resolveVALS(ref: string): string {
    try {
      const out = execFileSync('vals', ['get', ref], { encoding: 'utf8' });
      return String(out).trim();
    } catch (e: any) {
      const msg = e?.stderr?.toString?.() || e?.message || String(e);
      throw new Error(`Utils.resolveVALS failed: ${msg}`);
    }
  }

  /** Ensure .sops.yaml exists and references the provided GCP KMS key for given patterns. */
  public static ensureSopsConfig(params: { gcpKmsResourceId: string; patterns: string[] }) {
    const sopsPath = `${projectRoot}/.sops.yaml`;
    // If file already exists, do not modify – keep previously created keys and rules.
    if (fs.existsSync(sopsPath)) return;
    const uniquePatterns = Array.from(new Set((params.patterns || []).filter(Boolean)));
    const keyGroup = { gcp_kms: [{ resource_id: params.gcpKmsResourceId }] } as any;
    const cfg = {
      creation_rules: uniquePatterns.map(p => ({ path_regex: p, key_groups: [keyGroup] } as any)),
      stores: { yaml: { indent: 2 } },
    } as const;
    Utils.writeSopsConfig(sopsPath, cfg as any);
  }

  private static writeSopsConfig(pathname: string, cfg: { creation_rules: any[]; stores: { yaml: { indent: number } } }) {
    try {
      fs.writeFileSync(pathname, '# Generated by Pulumi\n' + YAML.stringify(cfg, { indent: 2 }));
    } catch {}
  }
}

export type BackendS3 = { type: 's3'; bucket?: string; region?: string; profile?: string; sharedConfigFiles?: string[] };
export type BackendGcs = { type: 'gcs'; bucket: string; location?: string };
export type BackendLocal = { type: 'file'; path?: string };
export type BackendConfig = BackendS3 | BackendGcs | BackendLocal;